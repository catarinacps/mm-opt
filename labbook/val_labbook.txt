Primeiramente, labbook em txt sim e pau no cu do emacs.

Segundamente:
Cada thread operando sobre seus pedaços das matrizes originais, porém não podem
operar sobre a mesma matriz final porque senão vai ter conflito.
Então uma ideia é que cada thread faça sua operação em uma matriz privada que
depois pode ser somada por meio de avx :)


Sobre máquina: blaise
Sobre o CPU: Intel Xeon E5-2699 v4 Broadwell
Referências:
https://en.wikichip.org/wiki/intel/microarchitectures/broadwell_(client)
https://en.wikichip.org/wiki/intel/xeon_e5#Broadwell_EP_.28v4.29

Sobre cache:
Tam de linha: 64 bytes, cabendo 16 números inteiros dentro de cada linha
(inteiros de 4 bytes)
Tam de cache: 32Kib (32.768 Bytes) 8-way
Número de linhas: 512 (32.768B/64B)
Número máximo de elementos que podem estar em cache: 8192 elementos de matrizes
(512*16)
Número máximo de elementos por matriz: 2730 pra cada matriz (8192/3)
Subconjuntos das matrizes principais precisam ser de no máximo 52x52 (sqrt(2730))
Tamanho de uma única matriz de 1024x1024: 4,19MB (1024x1024*4(bytes por
inteiro)) (2^22)
Linhas necessárias pra uma matriz de 1024x1024: 65.536 (2^22/2^6=2^16)

Ou seja, teremos subconjuntos das 3 matrizes principais em cache em um dado
momento. Cada subconjunto precisa ser de 52x52, para que se tenha no máximo 2730
elementos de cada subconjunto em cache (um máximo de 8192 elementos podem estar
em cache simultaneamente). Esses 2730 elementos de cada matriz, que totalizam
8192 elementos, utilizam os 32.768 Bytes da cache de dados.
(o 52x52 não dá exatamente 2730 elementos, então a cache não estaria sendo
totalmente utilizada).

Além disso, precisamos considerar eventuais variáveis utilizadas pelo código:
variáveis para iteração, ponteiros, etc. Como fazer isso?

Also: não utilizar SMT!


Sobre utilização de SIMD/AVX:
https://software.intel.com/en-us/articles/using-avx-without-writing-avx-code


01/10/19

Provavelmente tem um LRU lá, então é bom evitar thrashing. Evitar thrashing é
simplesmente garantir a divisão das matrizes em subconjuntos de tamanho bom.
Tentando entender como particionar. Pq se fizer em conjuntos quadrados, é
terrível: sem localidade, e não é assim que funciona na multiplicação:
A primeira coluna da matriz A vai multiplicar a primeira linha da matriz B.
Então é vantagem ter VER COM OS GURIS.
Na real, dividir em quadrados é inevitável pra que se aproveite a localidade
espacial: cabem 16 números por linha de cache, então as 1024 colunas com certeza
vão ser divididas em no mínimo conjuntos de 16 colunas


Memory Alignment:
Não tenho ideia de como cheguei nisso, mas:
A gente tem que alocar a memória de forma alinhada pra garantir que vão estar de
fato os 16 elementos inteiros na linha de cache. O malloc não garante isso.
https://embeddedartistry.com/blog/2017/2/20/implementing-aligned-malloc
https://linux.die.net/man/3/memalign <- função a ser usada (a POSIX, que é atual)

Also, se formos fazer diferentes subconjuntos alocados separadamente, tem que
tbm fazer essas alocações de forma alinhada.



Ideia:
- Uma otm de cache: blocking (separar em Subconjuntos).
- Paralelismo com OpenMP.

Ver como fazer com o particionamento pra entender como aproveitar isso no
paralelismo.


04/10/19

Queremos testar o uso da diretiva #pragma omp simd no código pra gerar código
SIMD sobre os for. Pra isso a gente vai adicionar a diretiva, compilar e fazer
objdump -d binary > binary.asm.
(não funcionou, não conseguimos gerar código com avx)

1º - memalign. não deu diferença pra execução normal, mas talvez dê efeito com
vetorização.

2º - alocação contínua.

3° - blocking???

4° - transposição da matriz b (de 81 pra 34)

5° - AVX: com -ftree-vectorize: ruim.

Info: com -O3 fica 19s
      com -O3 e matriz b transposta fica 5s
      código original fica 81s
      com -ftree-vectorize ficou 83



--march=native: indica que ta compilando nativamente pro comp saber detalhes
específicos da máquina. Pode ajudar nas insts avx. Não compila COM as insts, mas
enable a compilação com as insts avx. Pra de fato compilar COM avx: produces
code optmized (-mtune=native)
(não funcionou exatamente kkk)
