#+title: Lab-book do Henrique
#+author: Henrique Silva
#+email: hcpsilva@inf.ufrgs.br
#+infojs_opt:
#+property: session *R*
#+property: cache yes
#+property: results graphics
#+property: exports both
#+property: tangle yes

Primeiramente, lab-book em org sim (jeito certo) e pau no cu do txt.

* Sumário                                                             :TOC_3:
- [[#diário][Diário]]
  - [[#2019-09-29][2019-09-29]]
  - [[#2019-10-06][2019-10-06]]
- [[#otimizações][Otimizações]]
  - [[#particionamento-da-matriz-blocking][Particionamento da matriz (blocking)]]
  - [[#simd-no-loop-de-multiplicação][SIMD no loop de multiplicação]]
  - [[#alocação-contígua-da-matriz-em-memória][Alocação contígua da matriz em memória]]
  - [[#alinhar-a-memória-alocada][Alinhar a memória alocada]]
  - [[#transposição-da-matriz][Transposição da matriz]]
- [[#experimentos][Experimentos]]
  - [[#design][Design]]
  - [[#script][Script]]

* Diário

Anotações que não merecem tópicos só pra elas.

** 2019-09-29

Bom, algumas coisas que eu pensei agora depois de acordar:

- Fazer design fatorial completo dos experimentos (não são muitas variáveis,
  deve ser tranquilo)
- Achar otimizações de multiplicação de matrizes na internet deve ser tipo muito
  fácil então não vamos contar que nosso trab "vai ser muito mais do que eles
  peçam" por definição (i.e. qualquer um que sabe usar google vai acabar dando
  de cara com o particionamento e com openmp)

Acho que o mais chato vai ser multiplexar as otimizações que implementaremos.
Tipo, como desligar e ligar só as otimizações que a gente quer em tempo de
compilação? =#if=? Usar defines e =#ifndef= me parece que pode ficar bem chato
bem rapido.

** 2019-10-06

Então, hoje é o dia que eu espero testar o memalign e o simd do OpemMP de
novo.

Okay, eu acho que não dá pra vetorizar sem transpor a matriz. Como fazer o load
se os dados estão separados por um certo stride? Além disso, precisamos dizer
pro compilador que os ponteiros não são aliased pra ele confiar que a
vetorização é possível (keyword restrict).

O =#pragma omp simd= só passa a ter efeito quando o nível de otimização é -O1!!!
Resposta interessante no stack-overflow: [[https://stackoverflow.com/questions/32000917/c-loop-optimization-help-for-final-assignment-with-compiler-optimization-disabl/32001196#32001196][Why is -O0 bad]]

Vou ignorar o esquema da vetorização e focar na transposição e alinhamento.

Sem diferença usando ou não alinhamento de memória.

* Otimizações

Okay, pelo o que eu entendi a gente ta pensando nas seguintes otimizações:

** Particionamento da matriz (blocking)

Ainda não parei pra pensar como isso funcionaria. Juro que vou ler teu lab-book
okay Val.

** SIMD no loop de multiplicação

So far parece a mais simples. Incluir OpenMP e usar a diretiva =simd=.

** Alocação contígua da matriz em memória

Not sure como que isso conta como uma otimização. Parece mais um side-effect
desejável das outras otimizações, mas oh well.

Enfim, alocar a matriz continuamente em memória para evitar misses.

** Alinhar a memória alocada

Teoricamente da muito efeito?

** Transposição da matriz

Acessar uma coluna como se fosse uma linha (porque em memória é uma linha) ajuda
muito.

* Experimentos

Então, parece ser straightfoward enough mas é que pra fazer acontecer depende
muito de como a gente vai fazer pra compilar diferentes versões do nosso
código.

Quer dizer, sempre da pra fazer um brute force do problema e escrever um
executavel pra cada versão, right? (muito feio tho)

Okay, sobre experimentos:

#+begin_src R :session :results none
library(DoE.base)
library(tidyverse)
options(crayon.enabled=FALSE)
#+end_src

** Design

Seed randômica:

#+begin_src R :session :results value :exports results
floor(runif(1,1,99999))
#+end_src

#+RESULTS:
: 56753

Design:

#+begin_src R :session :results none
otim_1 = c("y", "n")
otim_2 = c("y", "n")
otim_3 = c("y", "n")
comp = c("-O0", "-O1", "-O2", "-O3")
cter = c("cycles", "L1-dcache-load-misses", "instructions", "l1d.replacement")

fac.design(
    nfactors=5,
    replications=30,
    repeat.only=FALSE,
    blocks=1,
    randomize=TRUE,
    seed=56753,
    factor.names=list(
      otimizacao_1=otim_1,
      otimizacao_2=otim_2,
      otimizacao_3=otim_3,
      counter=cter,
      compiler=comp)) %>%
  as_tibble %>%
  transmute(id = as.numeric(Blocks), otimizacao_1, otimizacao_2, otimizacao_3, counter, compiler) %>%
  write_delim("../experiments/runs.plan", delim=" ", col_names=FALSE)

# the space delimited file is to help with the posterior parsing in the shell
# script
#+end_src

** Script

Para a execução...

#+begin_src bash :shebang "#!/bin/bash" :tangle ../experiments/exp.slurm
#SBATCH --time=72:00:00
#SBATCH --chdir=$SCRATCH
#SBATCH --partition=draco
#SBATCH --nodes=1
#SBATCH --output=$HOME/slurm_outputs/%x_%j.out
#SBATCH --error=$HOME/slurm_outputs/%x_%j.err
#BATCH --mail-type=END,FAIL
#BATCH --mail-user=hcpsilva@inf.ufrgs.br

# parameters:
MACHINE="draco_32"
# the experiment ID, defined in the lab-book
EXP_ID=${@[0]}
# the experiment directory
EXP_DIR=${@[1]}

# experiment name (which is the ID and the machine and its core count)
EXP_NAME=${EXP_ID}_${MACHINE}

# not sure if I can trust the sbatch variable
cd $SCRATCH

# prepare our directory
mkdir $EXP_NAME
pushd $EXP_NAME

# copy the code folder
cp -r $EXP_DIR/.. code
pushd code

# execute the experiment
while read -r id otm1 otm2 otm3 counter comp; do
    echo "-> Parameters set to: $id $otm1 $otm2 $otm3 $comp"
    echo

    iteration_output=../results/${OTM1}_${OTM2}_${OTM3}_${counter}_${comp}_${id}

    # alocacao contigua
    if [[ $otm1 == "y" ]]; then
        OPT1="-DOTM_1"
    else
        OPT1=
    fi

    # matriz b transposta
    if [[ $otm2 == "y" ]]; then
        OPT2="-DOTM_2"
    else
        OPT2=
    fi

    # simd
    if [[ $otm3 == "y" ]]; then
        OPT3="-DOTM_3 -fopenmp -fopenmp-simd"
    else
        OPT3=
    fi

    make redo USED_OPT="$OPT1 $OPT2 $OPT3" COMP_OPT="$comp"

    ./build/mult_new 1024 1024 > $iteration_output.raw

    # stress the memory to prevent cache influence between runs
    stress-ng --vm 3 --vm-bytes 75% -t 5s &> /dev/null

    perf stat -o $iteration_output.perf -e $counter ./build/mult_new 1024 1024

    # stress the memory to prevent cache influence between runs
    stress-ng --vm 3 --vm-bytes 75% -t 5s &> /dev/null

    echo
done < $EXP_DIR/runs.plan

popd

tar czf $EXP_DIR/$EXP_NAME.tar.gz *

popd
rm -rf $SCRATCH/*
#+end_src
